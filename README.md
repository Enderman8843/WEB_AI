<img width="1919" height="677" alt="image" src="https://summer.hackclub.com/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsiZGF0YSI6NTkzMjIsInB1ciI6ImJsb2JfaWQifX0=--37be2eddde2f9f15abf6a0d2b0482e4e83dac40d/%F0%9D%9D%80%20(1).png" />
# Lanthanum.AI (Web_AI)
 Lanthanum.AI is a project with which the user can access small LLM models through web which would be running via WEB GPU and this doesn't require any kind of AI , Everything runs in local and nothing goes out of users pc.

 # Installation

 ```
git clone https://github.com/Enderman8843/WEB_AI
cd WEB_AI
npm run dev
  ```
 

 # Demo 
  https://lanthanum.vercel.app/?model=SmolLM2-360M-Instruct-q0f32-MLC

# 
 
