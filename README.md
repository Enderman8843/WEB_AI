<img width="1919" height="677" alt="image" src="https://summer.hackclub.com/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsiZGF0YSI6NTkzMjIsInB1ciI6ImJsb2JfaWQifX0=--37be2eddde2f9f15abf6a0d2b0482e4e83dac40d/%F0%9D%9D%80%20(1).png" />


# Lanthanum.AI (Web_AI)
 Lanthanum.AI is a project with which the user can access small LLM models through web which would be running via WEB GPU and this doesn't require any kind of AI , Everything runs in local and nothing goes out of users pc.

 # Installation

 ```
git clone https://github.com/Enderman8843/WEB_AI
cd WEB_AI
npm run dev
  ```
 

 # Demo 
  https://lanthanum.vercel.app/?model=SmolLM2-360M-Instruct-q0f32-MLC
  

# Compabality Issues
Lanthanum.AI is best recommened to run on Chromium based browser i.e Chrome and Edge  >= 113 , If using other broswers check this guide also this dosent work if your pc dosent support DirectX12


https://github.com/user-attachments/assets/80d817e6-eac3-40f4-8a08-299b0f8377aa



https://caniuse.com/webgpu 




 
